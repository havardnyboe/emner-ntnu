{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random; random.seed(123)\n",
    "import codecs\n",
    "import string\n",
    "import gensim\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1 & 1.2\n",
    "Henter inn dokumentet og splitter til en liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = codecs.open(\"pg3300.txt\", \"r\", \"utf-8\")\n",
    "paragraphs = f.read().split(\"\\r\\n\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.3\n",
    "Fjerner \"gutenberg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_sans_gutenberg = []\n",
    "for i in range(len(paragraphs)-1, -1, -1):\n",
    "    if not \"gutenberg\" in paragraphs[i].lower():\n",
    "        paragraphs_sans_gutenberg.append(paragraphs[i])\n",
    "\n",
    "paragraphs_sans_gutenberg.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.4\n",
    "Splitter paragrafene til ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for paragraph in paragraphs_sans_gutenberg:\n",
    "    words.append(paragraph.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.5 & 1.6\n",
    "Stemmer ordene og fjerner tegnsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words[i])):\n",
    "        words[i][j] = words[i][j].strip(string.punctuation+\"\\n\\r\\t\\ufeff\").lower()\n",
    "        words[i][j] = stemmer.stem(words[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1\n",
    "Lager en ordliste med ord og og stoppord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_words = gensim.corpora.Dictionary(words)\n",
    "stop_words = codecs.open(\"common-english-words.csv\", \"r\", \"utf-8\").read().split(\",\")\n",
    "stop_words_ids = []\n",
    "for stop_word in stop_words:\n",
    "    try:\n",
    "        stop_words_ids.append(dictionary_words.token2id[stop_word])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2\n",
    "Fjerner stoppord og lager corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_words.filter_tokens(stop_words_ids)\n",
    "corpus = [dictionary_words.doc2bow(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.180*\"thi\" + 0.167*\"those\" + 0.166*\"countri\" + 0.162*\"upon\" + 0.156*\"price\" + 0.155*\"hi\" + 0.151*\"more\" + 0.150*\"wa\" + 0.147*\"part\" + 0.145*\"great\"'), (1, '-0.777*\"0\" + -0.291*\"2\" + -0.286*\"1\" + -0.237*\"8\" + -0.197*\"4\" + -0.152*\"6\" + -0.114*\"10\" + -0.100*\"barrel\" + -0.093*\"£\" + -0.092*\"3\"'), (2, '0.687*\"chapter\" + 0.223*\"divis\" + 0.223*\"iv\" + 0.204*\"v\" + 0.191*\"iii\" + 0.183*\"ii\" + 0.159*\"stock\" + 0.150*\"labour\" + 0.116*\"book\" + 0.110*\"system\"')]\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = gensim.models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "matrix_similarities = gensim.similarities.MatrixSimilarity(tfidf_corpus)\n",
    "\n",
    "lsi_model = gensim.models.LsiModel(tfidf_corpus, id2word=dictionary_words, num_topics=100)\n",
    "lsi_corpus = lsi_model[tfidf_corpus]\n",
    "lsi_index = gensim.similarities.MatrixSimilarity(lsi_corpus)\n",
    "\n",
    "print(lsi_model.show_topics(num_topics=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.1 & 4.2\n",
    "Lager spørring og prosesserer den\n",
    "\n",
    "Lager BoW og TF-IDF representasjoner av spørringen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['function', 'money']\n",
      "money: 0.352, function: 0.936, "
     ]
    }
   ],
   "source": [
    "def preprocessing(text):\n",
    "    stop_words = codecs.open(\"common-english-words.csv\", \"r\", \"utf-8\").read().split(\",\")\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = gensim.utils.tokenize(text)\n",
    "    tokens = [stemmer.stem(token.strip(string.punctuation)) for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "query = preprocessing(\"What is the function of money?\")\n",
    "# query = preprocessing(\"How taxes influence Economics?\")\n",
    "print(\"Query:\", query)\n",
    "bow_query = dictionary_words.doc2bow(query)\n",
    "tfidf_query = tfidf_model[bow_query]\n",
    "\n",
    "for i in range(len(tfidf_query)):\n",
    "    print(f\"{dictionary_words[bow_query[i][0]]}: {tfidf_query[i][1]:.3f}\", end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.3\n",
    "Finner de 3 mest relevante dokumentene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paragraph: 29] [similarity: 0.124]\n",
      "\n",
      "CHAPTER IV.\n",
      "OF THE ORIGIN AND USE OF MONEY.\n",
      "[paragraph: 79] [similarity: 0.092]\n",
      "\n",
      "    \n",
      "      When the stock which a man possesses is no more than sufficient to\n",
      "      maintain him for a few days or a few weeks, he seldom thinks of deriving\n",
      "      any revenue from it. He consumes it as sparingly as he can, and\n",
      "[paragraph: 80] [similarity: 0.088]\n",
      "\n",
      "CHAPTER II.\n",
      "OF MONEY, CONSIDERED AS A PARTICULAR\n",
      "BRANCH OF THE GENERAL STOCK OF THE SOCIETY, OR OF THE EXPENSE OF MAINTAINING\n",
      "THE NATIONAL CAPITAL.\n"
     ]
    }
   ],
   "source": [
    "doc2similarity = sorted(enumerate(matrix_similarities[tfidf_query]), key=lambda kv: -kv[1])[:3]\n",
    "\n",
    "for doc_id, sim in doc2similarity:\n",
    "    print(f\"[paragraph: {doc_id}] [similarity: {sim:.3f}]\")\n",
    "    print(\"\\n\".join(paragraphs_sans_gutenberg[doc_id].split(\"\\n\")[:5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
